{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ewRDMsYEoTiHM1JMnKNDeiY2mBvfdOw4",
      "authorship_tag": "ABX9TyOlNAO7K4NodClMuofZEtay",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZohanaZuthi/1st-project/blob/main/Data_Processing_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing Libraries**"
      ],
      "metadata": {
        "id": "TE-XRRJsBPFj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RsCp8kkz_gF-"
      },
      "outputs": [],
      "source": [
        "# importing the libraries\n",
        "# In machine learning there are three kind of libraries that will be used\n",
        "#  for array numpy , for ploting pyplot from matplotlib, for matrics pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reading the data file**"
      ],
      "metadata": {
        "id": "bnkZc1KVBbhr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8ESxUS7hMTj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "at first we need to read the data file. then define the independent and the dependent variable. Here in the data.csv file , we will take the first three column as independent variable and the last column will be our dependent or prediction column.\n",
        "\n",
        "By using iloc function we locate the row:column range , here : means all the values will be included. then the next parameters defines the independent/dependent column, In x the last column will be excluded thats why :-1. But in y case only the last column will be included, that's why just -1"
      ],
      "metadata": {
        "id": "yqhs7JSLMK5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=pd.read_csv('Data.csv')"
      ],
      "metadata": {
        "id": "9Yx85fHUAkkX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=dataset.iloc[:,:-1].values\n",
        "y=dataset.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "94Eo-0feH16H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR5vTPVFBflm",
        "outputId": "6b766d9d-efca-460a-ceef-445db6ca0bde"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTxH4rlHNrX6",
        "outputId": "e64ed6eb-fff3-483f-9c0c-202d01b35eb8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Taking care of missing data**"
      ],
      "metadata": {
        "id": "zwZkN4f1O4jq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case we will use sicit learn. with this library we will fill all the missing valuess with average value."
      ],
      "metadata": {
        "id": "LEQyKxCIP7Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "# the instance of the class\n",
        "imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
        "# fit method will calculate the mean and also look for missing values\n",
        "# fit expects only numerical arguments not text\n",
        "# transform will replace the missing\n",
        "imputer.fit(x[:,1:3])\n",
        "# python excludes the last pointer after:\n",
        "\n",
        "# transform creates new updatedd matrix\n",
        "# so we need to replace the expected column with the matrices\n",
        "x[:,1:3]=imputer.transform(x[:,1:3])"
      ],
      "metadata": {
        "id": "5h4TthKLNvxv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU0pZZ9uSSuz",
        "outputId": "8fe8f5ec-43f6-4f54-b1c5-62532ad97f48"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Replacing non numerical value with binary numbers**"
      ],
      "metadata": {
        "id": "zCoIy49fa-d6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoding for Independent Variable**"
      ],
      "metadata": {
        "id": "qB-s8o0Xd877"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ],
      "metadata": {
        "id": "zZjusxHfSUGG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder='passthrough')\n",
        "# fit plus transform method\n",
        "x=np.array(ct.fit_transform(x))"
      ],
      "metadata": {
        "id": "9pcULFs6bg4q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTVygV3kdhRg",
        "outputId": "87d77a6e-db2c-44e1-8ff1-4cb26002783c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoding for Dependent Variables**"
      ],
      "metadata": {
        "id": "Rl4Vl82UeF9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this we need label"
      ],
      "metadata": {
        "id": "E6LMAaRQeQLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "y=le.fit_transform(y)"
      ],
      "metadata": {
        "id": "KUzgmj6ndi2k"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOUEsjIHeprS",
        "outputId": "d1ae9b00-e5b7-4791-a6ec-389e16e856e1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Splitting the Dataset into training and test dataset**"
      ],
      "metadata": {
        "id": "ybgv45C6faEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature scaling will be applied after the spliting. the future machine will expect 4 kind of data set x_train,y_train,x_test,y_test"
      ],
      "metadata": {
        "id": "N-oaXWTefkDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)"
      ],
      "metadata": {
        "id": "tIe4thWOerDL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "random_state=1 ensures that the splitting of data into training and testing sets is reproducible. When you set a specific value (e.g., 1), it initializes the random number generator in a consistent way every time you run the code, meaning you'll get the same split each time."
      ],
      "metadata": {
        "id": "zmA3xhijicdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8zhqHzfidXf",
        "outputId": "fc56ccb6-5bce-4473-e04c-b22064b5d956"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hYDebw_isfL",
        "outputId": "e4daced9-0a7b-4c7f-eb0d-c4c455c23612"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Jotty3QiwG9",
        "outputId": "79a6546e-0509-4152-df02-147135783ef8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT3THG9diyIm",
        "outputId": "74c4652a-0d5e-427c-966f-fc68129fb87f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature Scaling**"
      ],
      "metadata": {
        "id": "yN06ypjPjUJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general there are two types of feature scaling. Normalisation and Standardisation. Standardisation always works optimally"
      ],
      "metadata": {
        "id": "NJdjooMokUQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "x_train[:, 3:]=sc.fit_transform(x_train[:, 3:])\n",
        "x_test[:,3:]=sc.fit_transform(x_test[:,3:])"
      ],
      "metadata": {
        "id": "ElOYVbvBi1ia"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrtbpLWgsPiB",
        "outputId": "3fe7eaaf-7b73-44e5-9368-9b8e1b9223b1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578554 -1.0781259408412427]\n",
            " [0.0 1.0 0.0 -0.014117293757057846 -0.07013167641635404]\n",
            " [1.0 0.0 0.0 0.5667085065333239 0.6335624327104546]\n",
            " [0.0 0.0 1.0 -0.3045301939022487 -0.307866172742979]\n",
            " [0.0 0.0 1.0 -1.901801144700799 -1.4204636155515822]\n",
            " [1.0 0.0 0.0 1.1475343068237056 1.2326533634535488]\n",
            " [0.0 1.0 0.0 1.4379472069688966 1.5749910381638883]\n",
            " [1.0 0.0 0.0 -0.7401495441200352 -0.5646194287757336]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5ONG5sisV_3",
        "outputId": "83b6fb99-85bc-411c-8869-3636be198c6e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 -1.0 -1.0]\n",
            " [1.0 0.0 0.0 1.0 1.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k5GPcXEYsgTk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}